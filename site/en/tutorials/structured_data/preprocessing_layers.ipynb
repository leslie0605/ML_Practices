{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg02FZzDyEqd"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "2mapZ9afGJ69"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMYQvJuBi7MS"
      },
      "source": [
        "# Classify structured data using Keras preprocessing layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjFbdBldyEqf"
      },
      "source": [
        "## Import TensorFlow and other libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LklnLlt6yEqf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TKU7RyoQGVKB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c03831a-7df1-4670-f026-b160571957a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.17.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXvBvobayEqi"
      },
      "source": [
        "## Load the dataset and read it into a pandas DataFrame\n",
        "\n",
        "<a href=\"https://pandas.pydata.org/\" class=\"external\">pandas</a> is a Python library with many helpful utilities for loading and working with structured data. Use `tf.keras.utils.get_file` to download and extract the CSV file with the PetFinder.my mini dataset, and load it into a <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\" class=\"external\">DataFrame</a> with <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\" class=\"external\">`pandas.read_csv`</a>:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qJ4Ajn-YyEqj"
      },
      "outputs": [],
      "source": [
        "csv_file = 'data/diabetes_prediction_dataset.csv'\n",
        "dataframe = pd.read_csv(csv_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efa6910dfa5f"
      },
      "source": [
        "Inspect the dataset by checking the first five rows of the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3uiq4hoIGyXI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "d6386e2d-53fc-4a96-e9d6-87023a027d09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
              "0  Female  80.0             0              1           never  25.19   \n",
              "1  Female  54.0             0              0         No Info  27.32   \n",
              "2    Male  28.0             0              0           never  27.32   \n",
              "3  Female  36.0             0              0         current  23.45   \n",
              "4    Male  76.0             1              1         current  20.14   \n",
              "\n",
              "   HbA1c_level  blood_glucose_level  diabetes  \n",
              "0          6.6                  140         0  \n",
              "1          6.6                   80         0  \n",
              "2          5.7                  158         0  \n",
              "3          5.0                  155         0  \n",
              "4          4.8                  155         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b692704-9530-4d92-98e0-a883fbd0e28e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>smoking_history</th>\n",
              "      <th>bmi</th>\n",
              "      <th>HbA1c_level</th>\n",
              "      <th>blood_glucose_level</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>never</td>\n",
              "      <td>25.19</td>\n",
              "      <td>6.6</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Info</td>\n",
              "      <td>27.32</td>\n",
              "      <td>6.6</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>never</td>\n",
              "      <td>27.32</td>\n",
              "      <td>5.7</td>\n",
              "      <td>158</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Female</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>current</td>\n",
              "      <td>23.45</td>\n",
              "      <td>5.0</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male</td>\n",
              "      <td>76.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>current</td>\n",
              "      <td>20.14</td>\n",
              "      <td>4.8</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b692704-9530-4d92-98e0-a883fbd0e28e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b692704-9530-4d92-98e0-a883fbd0e28e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b692704-9530-4d92-98e0-a883fbd0e28e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-476b8da0-7c8a-4e49-9d90-21c411573c79\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-476b8da0-7c8a-4e49-9d90-21c411573c79')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-476b8da0-7c8a-4e49-9d90-21c411573c79 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataframe",
              "summary": "{\n  \"name\": \"dataframe\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Female\",\n          \"Male\",\n          \"Other\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.51683987161513,\n        \"min\": 0.08,\n        \"max\": 80.0,\n        \"num_unique_values\": 102,\n        \"samples\": [\n          29.0,\n          39.0,\n          16.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hypertension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"heart_disease\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoking_history\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"never\",\n          \"No Info\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.636783416649581,\n        \"min\": 10.01,\n        \"max\": 95.69,\n        \"num_unique_values\": 4247,\n        \"samples\": [\n          53.27,\n          32.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HbA1c_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0706720918832282,\n        \"min\": 3.5,\n        \"max\": 9.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          6.6,\n          5.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood_glucose_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40,\n        \"min\": 80,\n        \"max\": 300,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          140,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3zDbrozyEqq"
      },
      "source": [
        "## Create a target variable\n",
        "\n",
        "The original task in Kaggle's <a href=\"https://www.kaggle.com/c/petfinder-adoption-prediction\" class=\"external\">PetFinder.my Adoption Prediction competition</a> was to predict the speed at which a pet will be adopted (e.g. in the first week, the first month, the first three months, and so on).\n",
        "\n",
        "In this tutorial, you will simplify the task by transforming it into a binary classification problem, where you simply have to predict whether a pet was adopted or not.\n",
        "\n",
        "After modifying the `AdoptionSpeed` column, `0` will indicate the pet was not adopted, and `1` will indicate it was."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wmMDc46-yEqq"
      },
      "outputs": [],
      "source": [
        "# In the original dataset, `'AdoptionSpeed'` of `4` indicates\n",
        "# a pet was not adopted.\n",
        "dataframe['target'] = dataframe.pop('diabetes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp0NCbswyEqs"
      },
      "source": [
        "## Split the DataFrame into training, validation, and test sets\n",
        "\n",
        "The dataset is in a single pandas DataFrame. Split it into training, validation, and test sets using a, for example, 80:10:10 ratio, respectively:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XvSinthO8oMj"
      },
      "outputs": [],
      "source": [
        "train, val, test = np.split(dataframe.sample(frac=1), [int(0.8*len(dataframe)), int(0.9*len(dataframe))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "U02Q1moWoPwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a7bdae-4f7e-40ff-d413-5e8cbc9809d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80000 training examples\n",
            "10000 validation examples\n",
            "10000 test examples\n"
          ]
        }
      ],
      "source": [
        "print(len(train), 'training examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_7uVu-xyEqv"
      },
      "source": [
        "## Create an input pipeline using tf.data\n",
        "\n",
        "Next, create a utility function that converts each training, validation, and test set DataFrame into a `tf.data.Dataset`, then shuffles and batches the data.\n",
        "\n",
        "Note: If you were working with a very large CSV file (so large that it does not fit into memory), you would use the `tf.data` API to read it from disk directly. That is not covered in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7r4j-1lRyEqw"
      },
      "outputs": [],
      "source": [
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  df = dataframe.copy()\n",
        "  labels = df.pop('target')\n",
        "  df = {key: value.to_numpy()[:,tf.newaxis] for key, value in dataframe.items()}\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(batch_size)\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYxIXH579uS9"
      },
      "source": [
        "Now, use the newly created function (`df_to_dataset`) to check the format of the data the input pipeline helper function returns by calling it on the training data, and use a small batch size to keep the output readable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tYiNH-QI96Jo"
      },
      "outputs": [],
      "source": [
        "batch_size = 5\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nFYir6S8HgIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa00de9-19e4-4773-e7d8-db0c5b322f00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every feature: ['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level', 'target']\n",
            "A batch of ages: tf.Tensor(\n",
            "[[47.  ]\n",
            " [51.  ]\n",
            " [ 6.  ]\n",
            " [17.  ]\n",
            " [ 1.72]], shape=(5, 1), dtype=float64)\n",
            "A batch of targets: tf.Tensor([0 0 0 0 0], shape=(5,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "[(train_features, label_batch)] = train_ds.take(1)\n",
        "print('Every feature:', list(train_features.keys()))\n",
        "print('A batch of ages:', train_features['age'])\n",
        "print('A batch of targets:', label_batch )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geqHWW54Hmte"
      },
      "source": [
        "As the output demonstrates, the training set returns a dictionary of column names (from the DataFrame) that map to column values from rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v50jBIuj4gb"
      },
      "source": [
        "## Apply the Keras preprocessing layers\n",
        "\n",
        "The Keras preprocessing layers allow you to build Keras-native input processing pipelines, which can be used as independent preprocessing code in non-Keras workflows, combined directly with Keras models, and exported as part of a Keras SavedModel.\n",
        "\n",
        "In this tutorial, you will use the following four preprocessing layers to demonstrate how to perform preprocessing, structured data encoding, and feature engineering:\n",
        "\n",
        "- `tf.keras.layers.Normalization`: Performs feature-wise normalization of input features.\n",
        "- `tf.keras.layers.CategoryEncoding`: Turns integer categorical features into one-hot, multi-hot, or <a href=\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\" class=\"external\">tf-idf</a>\n",
        "dense representations.\n",
        "- `tf.keras.layers.StringLookup`: Turns string categorical values into integer indices.\n",
        "- `tf.keras.layers.IntegerLookup`: Turns integer categorical values into integer indices.\n",
        "\n",
        "You can learn more about the available layers in the [Working with preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) guide.\n",
        "\n",
        "- For _numerical features_ of the PetFinder.my mini dataset, you will use a `tf.keras.layers.Normalization` layer to standardize the distribution of the data.\n",
        "- For _categorical features_, such as pet `Type`s (`Dog` and `Cat` strings), you will transform them to multi-hot encoded tensors with `tf.keras.layers.CategoryEncoding`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twXBSxnT66o8"
      },
      "source": [
        "### Numerical columns\n",
        "\n",
        "For each numeric feature in the PetFinder.my mini dataset, you will use a `tf.keras.layers.Normalization` layer to standardize the distribution of the data.\n",
        "\n",
        "Define a new utility function that returns a layer which applies feature-wise normalization to numerical features using that Keras preprocessing layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "D6OuEKMMyEq1"
      },
      "outputs": [],
      "source": [
        "def get_normalization_layer(name, dataset):\n",
        "  # Create a Normalization layer for the feature.\n",
        "  normalizer = layers.Normalization(axis=None)\n",
        "\n",
        "  # Prepare a Dataset that only yields the feature.\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "  # Learn the statistics of the data.\n",
        "  normalizer.adapt(feature_ds)\n",
        "\n",
        "  return normalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVD--2WZ7vmh"
      },
      "source": [
        "### Categorical columns\n",
        "\n",
        "Pet `Type`s in the dataset are represented as strings—`Dog`s and `Cat`s—which need to be multi-hot encoded before being fed into the model. The `Age` feature\n",
        "\n",
        "Define another new utility function that returns a layer which maps values from a vocabulary to integer indices and multi-hot encodes the features using the `tf.keras.layers.StringLookup`, `tf.keras.layers.IntegerLookup`, and `tf.keras.CategoryEncoding` preprocessing layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GmgaeRjlDoUO"
      },
      "outputs": [],
      "source": [
        "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
        "  # Create a layer that turns strings into integer indices.\n",
        "  if dtype == 'string':\n",
        "    index = layers.StringLookup(max_tokens=max_tokens)\n",
        "  # Otherwise, create a layer that turns integer values into integer indices.\n",
        "  else:\n",
        "    index = layers.IntegerLookup(max_tokens=max_tokens)\n",
        "\n",
        "  # Prepare a `tf.data.Dataset` that only yields the feature.\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "  # Learn the set of possible values and assign them a fixed integer index.\n",
        "  index.adapt(feature_ds)\n",
        "\n",
        "  # Encode the integer indices.\n",
        "  encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
        "\n",
        "  # Apply multi-hot encoding to the indices. The lambda function captures the\n",
        "  # layer, so you can use them, or include them in the Keras Functional model later.\n",
        "  return lambda feature: encoder(index(feature))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiE0glOPkMyh"
      },
      "source": [
        "## Preprocess selected features to train the model on\n",
        "\n",
        "You have learned how to use several types of Keras preprocessing layers. Next, you will:\n",
        "\n",
        "- Apply the preprocessing utility functions defined earlier on 13 numerical and categorical features from the PetFinder.my mini dataset.\n",
        "- Add all the feature inputs to a list.\n",
        "\n",
        "As mentioned in the beginning, to train the model, you will use the PetFinder.my mini dataset's numerical (`'PhotoAmt'`, `'Fee'`) and categorical (`'Age'`, `'Type'`, `'Color1'`, `'Color2'`, `'Gender'`, `'MaturitySize'`, `'FurLength'`, `'Vaccinated'`, `'Sterilized'`, `'Health'`, `'Breed1'`) features.\n",
        "\n",
        "Note: If your aim is to build an accurate model, try a larger dataset of your own, and think carefully about which features are the most meaningful to include, and how they should be represented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj1GoHSZ9R3H"
      },
      "source": [
        "Earlier, you used a small batch size to demonstrate the input pipeline. Let's now create a new input pipeline with a larger batch size of 256:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Rcv2kQTTo23h"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bIGNYN2V7iR"
      },
      "source": [
        "Normalize the numerical features (the number of pet photos and the adoption fee), and add them to one list of inputs called `encoded_features`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Q3RBa51VkaAn"
      },
      "outputs": [],
      "source": [
        "all_inputs = {}\n",
        "encoded_features = []\n",
        "\n",
        "# Numerical features.\n",
        "for header in ['age','bmi','HbA1c_level','blood_glucose_level']:\n",
        "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
        "  normalization_layer = get_normalization_layer(header, train_ds)\n",
        "  encoded_numeric_col = normalization_layer(numeric_col)\n",
        "  all_inputs[header] = numeric_col\n",
        "  encoded_features.append(encoded_numeric_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVcUAFd6bvlT"
      },
      "source": [
        "Turn the integer categorical values from the dataset (the pet age) into integer indices, perform multi-hot encoding, and add the resulting feature inputs to `encoded_features`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "1FOMGfZflhoA"
      },
      "outputs": [],
      "source": [
        "hypertension_col = tf.keras.Input(shape=(1,), name='hypertension', dtype='int64')\n",
        "\n",
        "encoding_layer = get_category_encoding_layer(name='hypertension',\n",
        "                                             dataset=train_ds,\n",
        "                                             dtype='int64',\n",
        "                                             max_tokens=5)\n",
        "encoded_hypertension_col = encoding_layer(hypertension_col)\n",
        "all_inputs['hypertension'] = hypertension_col\n",
        "encoded_features.append(encoded_hypertension_col)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "heart_disease_col = tf.keras.Input(shape=(1,), name='heart_disease', dtype='int64')\n",
        "\n",
        "encoding_layer = get_category_encoding_layer(name='heart_disease',\n",
        "                                             dataset=train_ds,\n",
        "                                             dtype='int64',\n",
        "                                             max_tokens=5)\n",
        "encoded_heart_disease_col = encoding_layer(heart_disease_col)\n",
        "all_inputs['heart_disease'] = heart_disease_col\n",
        "encoded_features.append(encoded_heart_disease_col)"
      ],
      "metadata": {
        "id": "SX0rgYhQNi_7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYzynk6wdqKe"
      },
      "source": [
        "Repeat the same step for the string categorical values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "K8C8xyiXm-Ie"
      },
      "outputs": [],
      "source": [
        "categorical_cols = ['gender', 'smoking_history']\n",
        "\n",
        "for header in categorical_cols:\n",
        "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
        "  encoding_layer = get_category_encoding_layer(name=header,\n",
        "                                               dataset=train_ds,\n",
        "                                               dtype='string',\n",
        "                                               max_tokens=5)\n",
        "  encoded_categorical_col = encoding_layer(categorical_col)\n",
        "  all_inputs[header] = categorical_col\n",
        "  encoded_features.append(encoded_categorical_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHSnhz2fyEq3"
      },
      "source": [
        "## Create, compile, and train the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDGyN_wpo0XS"
      },
      "source": [
        "The next step is to create a model using the [Keras Functional API](https://www.tensorflow.org/guide/keras/functional). For the first layer in your model, merge the list of feature inputs—`encoded_features`—into one vector via concatenation with `tf.keras.layers.concatenate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "EtkwHC-akvcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42de622b-eff4-4be2-dcd8-6cacef1a3c94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_22>,\n",
              " <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_23>,\n",
              " <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_24>,\n",
              " <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_25>,\n",
              " <KerasTensor shape=(None, 3), dtype=float32, sparse=False, name=keras_tensor_27>,\n",
              " <KerasTensor shape=(None, 3), dtype=float32, sparse=False, name=keras_tensor_29>,\n",
              " <KerasTensor shape=(None, 4), dtype=float32, sparse=False, name=keras_tensor_31>,\n",
              " <KerasTensor shape=(None, 5), dtype=float32, sparse=False, name=keras_tensor_33>]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "encoded_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "6Yrj-_pr6jyL"
      },
      "outputs": [],
      "source": [
        "all_features = tf.keras.layers.concatenate(encoded_features)\n",
        "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "output = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "model = tf.keras.Model(all_inputs, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRLDRcYAefTA"
      },
      "source": [
        "Configure the model with Keras `Model.compile`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "GZDb_lJdelSg"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"],\n",
        "              run_eagerly=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CED6OStLyEq7"
      },
      "source": [
        "Next, train and test the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "OQfE3PC6yEq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b1fd2e-9a10-40cf-cf62-d95ed704db16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - accuracy: 0.8681 - loss: 0.4247 - val_accuracy: 0.9562 - val_loss: 0.1211\n",
            "Epoch 2/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.9509 - loss: 0.1431 - val_accuracy: 0.9606 - val_loss: 0.1115\n",
            "Epoch 3/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - accuracy: 0.9558 - loss: 0.1318 - val_accuracy: 0.9615 - val_loss: 0.1093\n",
            "Epoch 4/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.9589 - loss: 0.1230 - val_accuracy: 0.9627 - val_loss: 0.1079\n",
            "Epoch 5/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 58ms/step - accuracy: 0.9594 - loss: 0.1202 - val_accuracy: 0.9643 - val_loss: 0.1059\n",
            "Epoch 6/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.9597 - loss: 0.1205 - val_accuracy: 0.9637 - val_loss: 0.1041\n",
            "Epoch 7/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 59ms/step - accuracy: 0.9600 - loss: 0.1182 - val_accuracy: 0.9642 - val_loss: 0.1025\n",
            "Epoch 8/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.9606 - loss: 0.1151 - val_accuracy: 0.9646 - val_loss: 0.1010\n",
            "Epoch 9/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - accuracy: 0.9613 - loss: 0.1123 - val_accuracy: 0.9649 - val_loss: 0.0995\n",
            "Epoch 10/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 69ms/step - accuracy: 0.9618 - loss: 0.1104 - val_accuracy: 0.9653 - val_loss: 0.0984\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x782b49e20b10>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "model.fit(train_ds, epochs=10, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "T8N2uAdU2Cni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3300f13b-a428-489a-f382-56d18bf5dd6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9639 - loss: 0.0996\n",
            "{'accuracy': 0.9639000296592712, 'loss': 0.10164214670658112}\n"
          ]
        }
      ],
      "source": [
        "result = model.evaluate(test_ds, return_dict=True)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmZMnTKaCZda"
      },
      "source": [
        "## Perform inference\n",
        "\n",
        "The model you have developed can now classify a row from a CSV file directly after you've included the preprocessing layers inside the model itself.\n",
        "\n",
        "You can now [save and reload the Keras model](../keras/save_and_load.ipynb) with `Model.save` and `Model.load_model` before performing inference on new data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "QH9Zy1sBvwOH"
      },
      "outputs": [],
      "source": [
        "model.save('diabetes_prediction.keras')\n",
        "reloaded_model = tf.keras.models.load_model('diabetes_prediction.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D973plJrdwQ9"
      },
      "source": [
        "To get a prediction for a new sample, you can simply call the Keras `Model.predict` method. There are just two things you need to do:\n",
        "\n",
        "1.   Wrap scalars into a list so as to have a batch dimension (`Model`s only process batches of data, not single samples).\n",
        "2.   Call `tf.convert_to_tensor` on each feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "rKq4pxtdDa7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9462c4ee-d52f-4bde-e814-0ee9a40e21eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "This particular patient had a 78.5 percent probability of being diabetic.\n"
          ]
        }
      ],
      "source": [
        "sample = {\n",
        "    'gender': 'Female',\n",
        "    'age': 56.0,\n",
        "    'hypertension': 1,\n",
        "    'heart_disease': 0,\n",
        "    'smoking_history': 'never',\n",
        "    'bmi': 27.53,\n",
        "    'HbA1c_level': 8.1,\n",
        "    'blood_glucose_level': 77,\n",
        "}\n",
        "\n",
        "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
        "predictions = reloaded_model.predict(input_dict)\n",
        "prob = tf.nn.sigmoid(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This particular patient had a %.1f percent probability \"\n",
        "    \"of being diabetic.\" % (100 * prob)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJQQZEiH2FaB"
      },
      "source": [
        "Note: You will typically have better results with deep learning with larger and more complex datasets. When working with a small dataset, such as the simplified PetFinder.my one, you can use a <a href=\"https://developers.google.com/machine-learning/glossary#decision-tree\" class=\"external\">decision tree</a> or a <a href=\"https://developers.google.com/machine-learning/glossary#random-forest\" class=\"external\">random forest</a> as a strong baseline. The goal of this tutorial is to demonstrate the mechanics of working with structured data, so you have a starting point when working with your own datasets in the future.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "preprocessing_layers.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}